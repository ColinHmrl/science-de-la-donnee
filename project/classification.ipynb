{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-Zj_uw0HlNW"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import dotenv\n",
        "dotenv.load_dotenv('/tf/science-de-la-donnee/.env')\n",
        "\n",
        "# Changer les donn√©es dans le .enc pour le path\n",
        "data_multi_path = os.environ.get('DATA_MULTI_PATH')\n",
        "data_binary_path = os.environ.get('DATA_BINARY_PATH')\n",
        "script_path = os.environ.get('SCRIPT_PATH')\n",
        "weight_path = os.environ.get('WEIGHT_PATH')\n",
        "models_path = os.environ.get('MODELS_PATH')\n",
        "\n",
        "sys.path.insert(0, script_path)\n",
        "sys.path.insert(1, models_path)\n",
        "\n",
        "# scripts\n",
        "import plotResults\n",
        "import createTrainingData\n",
        "\n",
        "# models\n",
        "import resnet50\n",
        "import homemade\n",
        "# import vgg19\n",
        "import xception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GRRR Pawww\n",
        "\n",
        "# model_choosen = 'resnet50'\n",
        "# model_choosen = 'homemade'\n",
        "# model_choosen = 'vgg19'\n",
        "model_choosen = 'xception'\n",
        "\n",
        "image_h, image_w = 150, 150\n",
        "batch_size = 32\n",
        "min_h = 25\n",
        "min_w = 25\n",
        "\n",
        "epochs = 15\n",
        "\n",
        "# Si on veut faire une classification binaire ou multi\n",
        "binary = True\n",
        "\n",
        "if(binary):\n",
        "    data_dir = data_binary_path\n",
        "else:\n",
        "    data_dir = data_multi_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdapJ2Tua4X-"
      },
      "outputs": [],
      "source": [
        "# Alimentation des train/test set\n",
        "train_set, test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=.2,\n",
        "  subset='both',\n",
        "  image_size=(image_h, image_w),\n",
        "  seed=42,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_set.class_names\n",
        "num_classes = len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "match(model_choosen):\n",
        "    case 'resnet50':\n",
        "        model = resnet50.build((image_h, image_w), num_classes)\n",
        "    case 'homemade':\n",
        "        model = homemade.build((image_h, image_w), num_classes)\n",
        "    # case 'vgg19':\n",
        "    #     model = vgg19.build((image_h, image_w), num_classes)\n",
        "    # case 'xception':\n",
        "    #     model = xception.build((image_h, image_w), num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcKUUOArI60k",
        "outputId": "c1c59873-6a72-48e9-c58b-994cb6dbc80b"
      },
      "outputs": [],
      "source": [
        "path = createTrainingData.create_training_data(weight_path, model, model_choosen, num_classes, image_h, image_w, batch_size)\n",
        "\n",
        "checkpoint_path = path+\"/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "weights_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch')\n",
        "\n",
        "history = model.fit(train_set, epochs=epochs, validation_data=test_set, callbacks=[weights_callback])\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.savefig(path+\"/metrics.png\")\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load de la meilleur epoch\n",
        "model_to_load_path = weight_path+\"2023_10_03_14_29_27/cp-0013.ckpt\"\n",
        "\n",
        "model.load_weights(model_to_load_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_tests_images = []\n",
        "full_tests_labels = []\n",
        "for i,(batch_images, batch_labels) in enumerate(test_set):\n",
        "    for im in batch_images:\n",
        "        full_tests_images.append(im)\n",
        "    for res in batch_labels:\n",
        "        full_tests_labels.append(int(res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotResults.plot_results(num_classes == 2, predictions, full_tests_labels, full_tests_images, class_names, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tp = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "tn = 0\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    predicted_label = class_names[np.argmax(predictions[i])]\n",
        "    true_label = class_names[full_tests_labels[i]]\n",
        "    if(not binary):\n",
        "        if true_label == 'Photo' and predicted_label == 'Photo':\n",
        "            tp += 1\n",
        "        elif true_label == 'Photo' and predicted_label != 'Photo':\n",
        "            fn += 1\n",
        "        elif true_label != 'Photo' and predicted_label == 'Photo':\n",
        "            fp += 1\n",
        "        elif true_label != 'Photo' and predicted_label != 'Photo':\n",
        "            tn += 1\n",
        "\n",
        "        print(\"True positif: \", tp)\n",
        "        print(\"False positif: \", fp)\n",
        "        print(\"False negatif: \", fn)\n",
        "        print(\"True negatif: \", tn)\n",
        "        print('-------------------------------')\n",
        "\n",
        "\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "        print(\"Precision: \", precision)\n",
        "        print(\"Recall: \", recall)\n",
        "        print(\"F1: \", f1)\n",
        "        print(\"Accuracy: \", accuracy)\n",
        "        print('-------------------------------')\n",
        "        print(\"Confusion Matrix : \")\n",
        "        print(f\"[{tp}] [{fp}]\")\n",
        "        print(f\"[{fn}] [{tn}]\")\n",
        "\n",
        "\n",
        "        # Save all the metrics in a txt file\n",
        "        f = open(path+\"/metrics.txt\", \"w\")\n",
        "        f.write(\"True positif: \"+str(tp)+\"\\n\")\n",
        "        f.write(\"False positif: \"+str(fp)+\"\\n\")\n",
        "        f.write(\"False negatif: \"+str(fn)+\"\\n\")\n",
        "        f.write(\"True negatif: \"+str(tn)+\"\\n\")\n",
        "        f.write('-------------------------------\\n')\n",
        "        f.write(\"Precision: \"+str(precision)+\"\\n\")\n",
        "        f.write(\"Recall: \"+str(recall)+\"\\n\")\n",
        "        f.write(\"F1: \"+str(f1)+\"\\n\")\n",
        "        f.write(\"Accuracy: \"+str(accuracy)+\"\\n\")\n",
        "        f.write('-------------------------------\\n')\n",
        "        f.write(\"Confusion Matrix : \\n\")\n",
        "        f.write(f\"[{tp}] [{fp}]\\n\")\n",
        "        f.write(f\"[{fn}] [{tn}]\\n\")\n",
        "        f.close()\n",
        "        \n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
