{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-Zj_uw0HlNW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, '/home/cesi/datascience/scripts/')\n",
        "sys.path.insert(0, '/home/cesi/datascience/models/')\n",
        "import plotImages\n",
        "import resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sMOLa0eHrKE"
      },
      "outputs": [],
      "source": [
        "image_h, image_w = 150, 150\n",
        "batch_size = 32\n",
        "min_h = 25\n",
        "min_w = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83JggNKra3z5"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path('/home/cesi/datascience/data/livrable1_binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdapJ2Tua4X-"
      },
      "outputs": [],
      "source": [
        "def check_images(dir_path):\n",
        "    print('CHECK IMAGES:')\n",
        "    sub_dirs = os.listdir(dir_path)\n",
        "    for sub_dir_name in sub_dirs:\n",
        "      sub_dir_path = os.path.join(dir_path, sub_dir_name)\n",
        "      if not os.path.isdir(sub_dir_path): continue\n",
        "      print(\"-\",sub_dir_name.upper())\n",
        "      for file_name in tqdm(os.listdir(sub_dir_path)):\n",
        "          file_path = os.path.join(sub_dir_path, file_name)\n",
        "\n",
        "          if os.path.isfile(file_path):\n",
        "              # Check if the file is an image (you can add more image formats if needed)\n",
        "              if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                  try:\n",
        "                      with Image.open(file_path) as img:\n",
        "                       # if img.width < min_w or img.height < min_h:\n",
        "                       #   raise Exception(f'Too small img of shape {img.width},{img.height}')\n",
        "                        cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img_bytes = tf.io.read_file(file_path)\n",
        "                        tf.io.decode_image(img_bytes)\n",
        "                        img.verify()\n",
        "                  except Exception as e:\n",
        "                      #os.remove(file_path)\n",
        "                      print(f'\\nDeleting {file_path} due to an error: {str(e)}')\n",
        "              else:\n",
        "                #os.remove(file_path)\n",
        "                print(f'\\nSkipped {file_path} due to bad type {file_name.lower()}')\n",
        "#check_images(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSnl3XKhHtkC",
        "outputId": "eddd8a7a-b9ca-4088-cd2d-b145e0338e54"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=.2,\n",
        "  subset='both',\n",
        "  image_size=(image_h, image_w),\n",
        "  seed=42,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "class_names = train_set.class_names\n",
        "num_classes = len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classic_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip('horizontal', input_shape=(image_h, image_w, 3)),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "\n",
        "\n",
        "    tf.keras.layers.Rescaling(1./255, input_shape=(image_h, image_w, 3)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "    tf.keras.layers.Dense(len(class_names))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDHe6QE4IXfM"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "  \"classic\": classic_model,  \n",
        "  \"resnet50\": model_resnet_50\n",
        "}\n",
        "\n",
        "model_name = 'resnet50'\n",
        "model = models[model_name]\n",
        "from_logits = True\n",
        "if model_name != 'classic':\n",
        "    from_logits = False\n",
        "\n",
        "# compile the model for a binary classification problem\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=from_logits),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcKUUOArI60k",
        "outputId": "c1c59873-6a72-48e9-c58b-994cb6dbc80b"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# timestamp de debut\n",
        "folder = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "path = \"/home/cesi/datascience/project/weights/\"+folder\n",
        "# datetime object containing current date and time\n",
        "folder = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "# readme \n",
        "content = f\"\"\"# Training nÂ°{folder}\n",
        "number of classes: {num_classes}\n",
        "model: {model_name}\n",
        "image size: {image_h}x{image_w}\n",
        "batch size: {batch_size}\n",
        "backbone: {model.layers}\n",
        "## Summary\n",
        "{model.summary()}\n",
        "\n",
        "## Compile config\n",
        "{model.get_compile_config()}\n",
        "\"\"\"\n",
        "\n",
        "file_path = os.path.join(path, \"README.txt\")\n",
        "\n",
        "# Write the string to the text file\n",
        "with open(file_path, \"w\") as text_file:\n",
        "    text_file.write(content)\n",
        "\n",
        "\n",
        "epochs=15\n",
        "\n",
        "checkpoint_path = path+\"/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "weights_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch')\n",
        "\n",
        "history = model.fit(train_set, epochs=epochs, validation_data=test_set, callbacks=[weights_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_range = range(epochs)\n",
        "\n",
        "acc = history['history']['accuracy']\n",
        "val_acc = history['history']['val_accuracy']\n",
        "\n",
        "loss = history['history']['loss']\n",
        "val_loss = history['history']['val_loss']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.savefig(path+\"/metrics.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_to_load_path = '/home/cesi/datascience/project/weights/2023_10_02_07_55_21/cp-0004.ckpt'\n",
        "model.load_weights(model_to_load_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(test_set)\n",
        "if from_logits:\n",
        "    predictions = tf.nn.softmax(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_tests_images = []\n",
        "full_tests_labels = []\n",
        "for i,(batch_images, batch_labels) in enumerate(test_set):\n",
        "    for im in batch_images:\n",
        "        full_tests_images.append(im)\n",
        "    for res in batch_labels:\n",
        "        full_tests_labels.append(int(res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_image(prediction_array, true_label, img, class_names):\n",
        "  img = img/255.0\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "  predicted_label = np.argmax(prediction_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(prediction_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_image_binary(prediction_array, true_label, img, class_names):\n",
        "  img = img/255.0\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "  if prediction_array[0] > 0.5:\n",
        "    predicted_label = 1\n",
        "  else:\n",
        "    predicted_label = 0\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(prediction_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "  \n",
        "def plot_value_array(predictions_array, true_label):\n",
        "  plt.grid(False)\n",
        "  plt.xticks(num_classes)\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(num_classes), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')\n",
        "\n",
        "\n",
        "def plot_value_array_binary(predictions_array, true_label):\n",
        "  plt.grid(False)\n",
        "  plt.xticks([0,1])\n",
        "  plt.yticks([])\n",
        "  predictions_array = [1 - predictions_array[0], predictions_array[0]]\n",
        "  thisplot = plt.bar(range(num_classes), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "\n",
        "  if predictions_array[0] > 0.5:\n",
        "    predicted_label = 1\n",
        "  else:\n",
        "    predicted_label = 0\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')\n",
        "\n",
        "\n",
        "def plot_results(binary, predictions, full_tests_labels, full_tests_images, class_names, index_shift, num_rows, num_cols):\n",
        "  num_rows = 45  \n",
        "  num_cols = 5 \n",
        "  plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "  if binary:\n",
        "    for i in range(64):\n",
        "      i += index_shift\n",
        "      plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "      plot_image_binary(predictions[i], full_tests_labels[i], full_tests_images[i], class_names)\n",
        "\n",
        "      plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "      plot_value_array_binary(predictions[i], full_tests_labels[i])\n",
        "  else:\n",
        "    for i in range(64):\n",
        "        i += index_shift\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "        plot_image_binary(predictions[i], full_tests_labels[i], full_tests_images[i], class_names)\n",
        "\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "        plot_value_array_binary(predictions[i], full_tests_labels[i])\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_results(num_classes == 2, predictions, full_tests_labels, full_tests_images, class_names, 0, 45, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tp = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "tn = 0\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    predicted_label = class_names[np.argmax(predictions[i])]\n",
        "    true_label = class_names[full_tests_labels[i]]\n",
        "\n",
        "    if true_label == 'Non-photo' and predicted_label == 'Non-photo':\n",
        "        tp += 1\n",
        "    elif true_label == 'Non-photo' and predicted_label != 'Non-photo':\n",
        "        fn += 1\n",
        "    elif true_label != 'Non-photo' and predicted_label == 'Non-photo':\n",
        "        fp += 1\n",
        "    elif true_label != 'Non-photo' and predicted_label != 'Non-photo':\n",
        "        tn += 1    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tp, fp, fn, tn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "print(precision, recall, f1, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix : \")\n",
        "print(f\"[{tp}] [{fp}]\")\n",
        "print(f\"[{fn}] [{tn}]\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
