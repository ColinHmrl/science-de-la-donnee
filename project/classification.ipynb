{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-Zj_uw0HlNW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import dotenv\n",
        "dotenv.load_dotenv('/tf/science-de-la-donnee/.env')\n",
        "\n",
        "# Changer les donn√©es dans le .enc pour le path\n",
        "data_multi_path = os.environ.get('DATA_MULTI_PATH')\n",
        "data_binary_path = os.environ.get('DATA_BINARY_PATH')\n",
        "script_path = os.environ.get('SCRIPT_PATH')\n",
        "weight_path = os.environ.get('WEIGHT_PATH')\n",
        "models_path = os.environ.get('MODELS_PATH')\n",
        "\n",
        "sys.path.insert(0, script_path)\n",
        "sys.path.insert(1, models_path)\n",
        "\n",
        "# scripts\n",
        "import plotResults\n",
        "import createTrainingData\n",
        "\n",
        "# models\n",
        "import resnet50\n",
        "import homemade\n",
        "# import vgg19\n",
        "# import xception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GRRR Pawww\n",
        "\n",
        "# model_choosen = 'resnet50'\n",
        "model_choosen = 'homemade'\n",
        "# model_choosen = 'vgg19'\n",
        "# model_choosen = 'xception'\n",
        "\n",
        "image_h, image_w = 150, 150\n",
        "batch_size = 32\n",
        "min_h = 25\n",
        "min_w = 25\n",
        "\n",
        "epochs = 15\n",
        "\n",
        "# Si on veut faire une classification binaire ou multi\n",
        "binary = True\n",
        "\n",
        "if(binary):\n",
        "    data_dir = data_binary_path\n",
        "else:\n",
        "    data_dir = data_multi_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdapJ2Tua4X-"
      },
      "outputs": [],
      "source": [
        "# Alimentation des train/test set\n",
        "train_set, test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=.2,\n",
        "  subset='both',\n",
        "  image_size=(image_h, image_w),\n",
        "  seed=42,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_set.class_names\n",
        "num_classes = len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "match(model_choosen):\n",
        "    case 'resnet50':\n",
        "        model = resnet50.build((image_h, image_w), num_classes)\n",
        "    case 'homemade':\n",
        "        model = homemade.build((image_h, image_w), num_classes)\n",
        "    # case 'vgg19':\n",
        "    #     model = vgg19.build((image_h, image_w), num_classes)\n",
        "    # case 'xception':\n",
        "    #     model = xception.build((image_h, image_w), num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcKUUOArI60k",
        "outputId": "c1c59873-6a72-48e9-c58b-994cb6dbc80b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Corrupt JPEG data: 419 extraneous bytes before marker 0xd9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7: saving model to /tf/dataset/livrable1/weight/2023_10_03_13_11_25/cp-0007.ckpt\n",
            "1035/1035 [==============================] - 221s 212ms/step - loss: 0.2270 - accuracy: 0.9015 - val_loss: 0.2255 - val_accuracy: 0.9060\n",
            "Epoch 8/15\n",
            "1035/1035 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9092"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-03 13:38:38.694296: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
            "Corrupt JPEG data: 419 extraneous bytes before marker 0xd9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8: saving model to /tf/dataset/livrable1/weight/2023_10_03_13_11_25/cp-0008.ckpt\n",
            "1035/1035 [==============================] - 208s 199ms/step - loss: 0.2159 - accuracy: 0.9092 - val_loss: 0.1970 - val_accuracy: 0.9193\n",
            "Epoch 9/15\n",
            "1035/1035 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9131"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-03 13:42:07.747750: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
            "Corrupt JPEG data: 419 extraneous bytes before marker 0xd9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9: saving model to /tf/dataset/livrable1/weight/2023_10_03_13_11_25/cp-0009.ckpt\n",
            "1035/1035 [==============================] - 210s 202ms/step - loss: 0.2065 - accuracy: 0.9131 - val_loss: 0.2304 - val_accuracy: 0.8984\n",
            "Epoch 10/15\n"
          ]
        }
      ],
      "source": [
        "path = createTrainingData.create_training_data(weight_path, model, model_choosen, num_classes, image_h, image_w, batch_size)\n",
        "\n",
        "checkpoint_path = path+\"/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "weights_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch')\n",
        "\n",
        "history = model.fit(train_set, epochs=epochs, validation_data=test_set, callbacks=[weights_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_range = range(epochs)\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.savefig(path+\"/metrics.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load de la meilleur epoch\n",
        "model_to_load_path = weight_path+\"2023_10_03_11_26_35/cp-0004.ckpt\"\n",
        "\n",
        "model.load_weights(model_to_load_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_tests_images = []\n",
        "full_tests_labels = []\n",
        "for i,(batch_images, batch_labels) in enumerate(test_set):\n",
        "    for im in batch_images:\n",
        "        full_tests_images.append(im)\n",
        "    for res in batch_labels:\n",
        "        full_tests_labels.append(int(res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotResults.plot_results(num_classes == 2, predictions, full_tests_labels, full_tests_images, class_names, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tp = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "tn = 0\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    predicted_label = class_names[np.argmax(predictions[i])]\n",
        "    true_label = class_names[full_tests_labels[i]]\n",
        "\n",
        "    if true_label == 'Photo' and predicted_label == 'Photo':\n",
        "        tp += 1\n",
        "    elif true_label == 'Photo' and predicted_label != 'Photo':\n",
        "        fn += 1\n",
        "    elif true_label != 'Photo' and predicted_label == 'Photo':\n",
        "        fp += 1\n",
        "    elif true_label != 'Photo' and predicted_label != 'Photo':\n",
        "        tn += 1    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tp, fp, fn, tn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "print(precision, recall, f1, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix : \")\n",
        "print(f\"[{tp}] [{fp}]\")\n",
        "print(f\"[{fn}] [{tn}]\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
