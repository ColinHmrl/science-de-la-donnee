{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11BualWM3z2V"
   },
   "source": [
    "## 1.2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umQTZ2yN3z2W",
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import numpy as np\n",
    "# (x_train, _), (x_test, _) = tf.keras.utils.image_dataset_from_directory(\n",
    "\n",
    "# Configurations principales de nos modèles\n",
    "IMG_SIZE          = 448             # taille coté final d'une image en pixel (ici 28x28)\n",
    "NB_EPOCHS_DENOISE = 10               # nombre epoch alogithme debruiter\n",
    "BATCH_SIZE        = 8             # taille batch de traitement\n",
    "SAV_MODEL_DENOISE = \"denoiser.h5\"     # sauvegarde du modele de debruitage\n",
    "\n",
    "def process(image):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Import du .env\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "# Chargement du .env !!!!!!!!!!!! CHANGER LE PATH !!!!!!!!!!!!!!\n",
    "# Renvoie true si le .env est chargé\n",
    "dotenv.load_dotenv('/tf/science-de-la-donnee/.env')\n",
    "\n",
    "SOURCE_LIVRABLE2_PATH = os.getenv(\"SOURCE_LIVRABLE2_PATH\")\n",
    "print(SOURCE_LIVRABLE2_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = image_dataset_from_directory(\n",
    "    SOURCE_LIVRABLE2_PATH,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    # label_mode=None,\n",
    "    shuffle=False,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\"\n",
    "    )\n",
    "\n",
    "x_test = image_dataset_from_directory(\n",
    "    SOURCE_LIVRABLE2_PATH,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    # label_mode=None,\n",
    "    shuffle=False,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\"\n",
    "    )\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "x_train = x_train.map(lambda x,y: (x/255,y))\n",
    "x_test = x_test.map(lambda x,y: (x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ./photoOnly/Photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpI6DFBd3z2Y"
   },
   "source": [
    "Commençons par écrire une fonction qui permet de visualiser $n$ premiers enregistrements en noir et blanc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHzo3fUG3z2Y"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# os.chdir(r'/tf')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_noise(img, noise_factor=25):\n",
    "    noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=noise_factor/255, dtype=tf.float32)\n",
    "    noised_img = tf.cast(img, tf.float32) + noise\n",
    "    # noised_img = tf.clip_by_value(noised_img, clip_value_min=0.0, clip_value_max=1.0)\n",
    "    # noised_img = noised_img /255\n",
    "    # img = img /255\n",
    "    return noised_img, img\n",
    "\n",
    "#  divide by 255\n",
    "\n",
    "\n",
    "x_train_noisy = x_train.map(lambda x,y: (add_noise(x, 40)))\n",
    "x_test_noisy = x_test.map(lambda x,y: (add_noise(x, 40)))\n",
    "\n",
    "\n",
    "def display_images(X, n):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    # print(X.shape)\n",
    "    for i in range(n):\n",
    "    #A COMPLETER\n",
    "        # print(X[i].shape)\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "                         #A COMPLETER\n",
    "        plt.imshow(X[i])\n",
    "                   #A COMPLETER\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_images(list(x_train_noisy.take(1).as_numpy_iterator())[0][0], n=1)\n",
    "display_images(list(x_train.take(1).as_numpy_iterator())[0][0], n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uLTS74F3z2Z"
   },
   "source": [
    "Voyons ce que ça donne :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PC02d4V3z2s",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "\n",
    "# The encoding process\n",
    "input_img = Input(shape=(IMG_SIZE, IMG_SIZE, 3))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "# Encoding #\n",
    "\n",
    "# Conv1 #\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)  # 16 filters, 3x3 kernel\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)  # Pooling with 2x2 grid\n",
    "\n",
    "# Conv2 #\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)  # 8 filters, 3x3 kernel\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)  # Pooling with 2x2 grid\n",
    "\n",
    "\n",
    "# Note:\n",
    "# padding is a hyper-arameter for either 'valid' or 'same'. \n",
    "# \"valid\" means \"no padding\". \n",
    "# \"same\" results in padding the input such that the output has the same length as the original input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyHcMJFB3z2t"
   },
   "source": [
    "###### Décodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NHn8Hi53z2u"
   },
   "source": [
    "Passon au décodeur. Écrivez un code qui permet de décoder une image encodée selon l'architecture du réseau de neurones décrite auparavent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e48zjUuG3z2u",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)  # 8 filters, 3x3 kernel\n",
    "x = UpSampling2D((2, 2))(x)  # Upsampling to 2x2 grid\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)  # 16 filters, 3x3 kernel\n",
    "x = UpSampling2D((2, 2))(x)  # Upsampling to 2x2 grid\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)  # 1 filter to match input, 3x3 kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jomiZrm3z23",
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "outputId": "6140a07b-7eb4-406c-e4a9-29fdff0cc4b5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4w2DyFE3z3M"
   },
   "source": [
    "###### Entrainement de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHnPwSlj3z3N"
   },
   "source": [
    "On va ensuite entraîner l'auto-encodeur en utilisant les constantes définit au début (`NB_EPOCHS_DENOISE,BATCH_SIZE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLeiM12J7shx",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZEugG4_AKzb"
   },
   "source": [
    "Affichez maintenant la courbe d'apprentissage. Que pensez-vous des performances du modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(\n",
    "    x_train_noisy,\n",
    "    epochs=NB_EPOCHS_DENOISE,\n",
    "    shuffle=True,\n",
    "    validation_data=x_test_noisy,\n",
    "    # callbacks=[tf.keras.callbacks.TensorBoard(log_dir='./tmp/autoencoder')]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(list(x_test_noisy.take(1).as_numpy_iterator())[0][0], n=1)\n",
    "display_images(pred, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Oib6nOUB_t-A",
    "outputId": "5bbf833e-0879-4dd6-f290-3e4b604f971d"
   },
   "outputs": [],
   "source": [
    "# Visualisation des pertes d'apprentissage (Train) et de validation (Test)\n",
    "plt.plot( #A COMPLETER\n",
    "         label='train')\n",
    "plt.plot( #A COMPLETER\n",
    "         label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isdgF8Fw3z3W"
   },
   "source": [
    "Que pensez-vous des performances du modèle ?\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "\n",
    "# 1.4 Sauvgarde de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lacVdNs93z3Y"
   },
   "source": [
    "L'entrainement de l'auto-encodeur sans utilisation de puissance de calcul (GPU) peut prendre beaucoup de temps. Usuellement, nous sauvegardons le modèle entraîné en local ou sur un serveur distant pour l'utiliser ultérieurement afin de traiter les nouvelles données (d'ailleurs, vous verrez une utilisation avancée de cette technique, le transfert learning, dès la semaine prochaine).\n",
    "Pour sauvegarder le modèle `autoencoder`, utiliser la méthode `save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH0sl-AZ3z3Z"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "#A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgZ7ckxd3z3a"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = #A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "qjbGN2FX3z3a",
    "outputId": "b96c53b9-2af7-4f7d-8ab5-9fd55ae77504"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IEX6qSH3z3b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "sgKOfLjd3z3b"
   ],
   "name": "WS 2.3 - Autoencodeur et traitement d'image- Tuteur.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
