{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11BualWM3z2V"
   },
   "source": [
    "## 1.2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umQTZ2yN3z2W",
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "# Configurations principales de nos modèles\n",
    "IMG_SIZE          = 224             # taille coté final d'une image en pixel (ici 28x28)\n",
    "NB_EPOCHS_DENOISE = 40               # nombre epoch alogithme debruiter\n",
    "BATCH_SIZE        = 8            # taille batch de traitement\n",
    "SAVE_MODEL_DENOISE = \"denoiser.h5\"     # sauvegarde du modele de debruitage\n",
    "\n",
    "def process(image):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Import du .env\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "# Chargement du .env !!!!!!!!!!!! CHANGER LE PATH !!!!!!!!!!!!!!\n",
    "# Renvoie true si le .env est chargé\n",
    "dotenv.load_dotenv('/home/cesi/datascience/.env.local')\n",
    "\n",
    "models_path = os.environ.get('MODELS_PATH_LIVRABLE2')\n",
    "sys.path.insert(0, models_path)\n",
    "\n",
    "import builder_vae\n",
    "import homemade\n",
    "import test2\n",
    "\n",
    "\n",
    "SAVE_WEIGHTS_PATH = os.environ.get('WEIGHT_PATH_LIVRABLE2')\n",
    "SOURCE_LIVRABLE2_PATH = os.getenv(\"SOURCE_LIVRABLE2_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test = image_dataset_from_directory(\n",
    "    SOURCE_LIVRABLE2_PATH,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    # label_mode=None,\n",
    "    shuffle=False,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "x_train = x_train.map(lambda x,y: (x/255,y))\n",
    "x_test = x_test.map(lambda x,y: (x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ./photoOnly/Photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpI6DFBd3z2Y"
   },
   "source": [
    "Commençons par écrire une fonction qui permet de visualiser $n$ premiers enregistrements en noir et blanc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHzo3fUG3z2Y"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# os.chdir(r'/tf')\n",
    "from keras_cv.layers import RandomGaussianBlur\n",
    "from random import randint, seed\n",
    "\n",
    "def add_noise(img, noise_factor=25, blur_factor=5):\n",
    "    r = tf.experimental.numpy.random.randint(1, 4)\n",
    "    noised_img = img\n",
    "    # if r == 1:\n",
    "    #     noised_img = RandomGaussianBlur(kernel_size=3, factor=(0.5, 2))(img)\n",
    "    # elif r == 2:\n",
    "    #     noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=noise_factor/255, dtype=tf.float32)\n",
    "    #     noised_img = tf.cast(img, tf.float32) + noise\n",
    "    # elif r == 3:\n",
    "    noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=noise_factor/255, dtype=tf.float32)\n",
    "    noised_img = tf.cast(img, tf.float32) + noise\n",
    "    noised_img = RandomGaussianBlur(kernel_size=5, factor=(0.5, blur_factor))(noised_img)\n",
    "    return noised_img, img\n",
    "\n",
    "#  divide by 255\n",
    "\n",
    "\n",
    "x_train_noisy = x_train.map(lambda x,y: (add_noise(x, 15, 1.5)))\n",
    "x_test_noisy = x_test.map(lambda x,y: (add_noise(x, 15, 1.5)))\n",
    "\n",
    "\n",
    "def display_images(X, n):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    # print(X.shape)\n",
    "    for i in range(n):\n",
    "    #A COMPLETER\n",
    "        # print(X[i].shape)\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "                         #A COMPLETER\n",
    "        plt.imshow(X[i])\n",
    "                   #A COMPLETER\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(list(x_train_noisy.take(1).as_numpy_iterator())[0][0], n=2)\n",
    "display_images(list(x_train.take(1).as_numpy_iterator())[0][0], n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uLTS74F3z2Z"
   },
   "source": [
    "Voyons ce que ça donne :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PC02d4V3z2s",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_CHOSEN = \"test2\"\n",
    "\n",
    "def load_model(model_choosen):\n",
    "    match(model_choosen):\n",
    "        case 'homemade':\n",
    "            model = homemade.build(IMG_SIZE)\n",
    "        case 'vae':\n",
    "            model = builder_vae.build(IMG_SIZE, 64)\n",
    "        case 'test2':\n",
    "            model = test2.build(IMG_SIZE)\n",
    "    return model\n",
    "autoencoder = load_model(MODEL_CHOSEN)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4w2DyFE3z3M"
   },
   "source": [
    "###### Entrainement de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHnPwSlj3z3N"
   },
   "source": [
    "On va ensuite entraîner l'auto-encodeur en utilisant les constantes définit au début (`NB_EPOCHS_DENOISE,BATCH_SIZE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLeiM12J7shx",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# path = createTrainingData.create_training_data(weight_path, model, model_choosen, num_classes, image_h, image_w, batch_size)\n",
    "\n",
    "# checkpoint_path = path+\"/cp-{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# weights_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_path,\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     save_freq='epoch')\n",
    "\n",
    "# history = model.fit(train_set, epochs=epochs, validation_data=test_set, callbacks=[weights_callback])\n",
    "\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    x_train_noisy,\n",
    "    epochs=1,\n",
    "    shuffle=True,\n",
    "    validation_data=x_test_noisy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZEugG4_AKzb"
   },
   "source": [
    "Affichez maintenant la courbe d'apprentissage. Que pensez-vous des performances du modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_path = SAVE_WEIGHTS_PATH + 'TO_\\CHANGE/weights.h5' \n",
    "autoencoder.save_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(x_test_noisy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(list(x_test_noisy.take(1).as_numpy_iterator())[0][0], n=1)\n",
    "display_images(pred, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Oib6nOUB_t-A",
    "outputId": "5bbf833e-0879-4dd6-f290-3e4b604f971d"
   },
   "outputs": [],
   "source": [
    "# Visualisation des pertes d'apprentissage (Train) et de validation (Test)\n",
    "plt.plot( #A COMPLETER\n",
    "         label='train')\n",
    "plt.plot( #A COMPLETER\n",
    "         label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isdgF8Fw3z3W"
   },
   "source": [
    "Que pensez-vous des performances du modèle ?\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "\n",
    "# 1.4 Sauvgarde de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lacVdNs93z3Y"
   },
   "source": [
    "L'entrainement de l'auto-encodeur sans utilisation de puissance de calcul (GPU) peut prendre beaucoup de temps. Usuellement, nous sauvegardons le modèle entraîné en local ou sur un serveur distant pour l'utiliser ultérieurement afin de traiter les nouvelles données (d'ailleurs, vous verrez une utilisation avancée de cette technique, le transfert learning, dès la semaine prochaine).\n",
    "Pour sauvegarder le modèle `autoencoder`, utiliser la méthode `save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH0sl-AZ3z3Z"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "#A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgZ7ckxd3z3a"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = #A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "qjbGN2FX3z3a",
    "outputId": "b96c53b9-2af7-4f7d-8ab5-9fd55ae77504"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IEX6qSH3z3b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "sgKOfLjd3z3b"
   ],
   "name": "WS 2.3 - Autoencodeur et traitement d'image- Tuteur.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
