{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11BualWM3z2V"
   },
   "source": [
    "## 1.2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umQTZ2yN3z2W",
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "# Configurations principales de nos modèles\n",
    "IMG_SIZE          = 400             # taille coté final d'une image en pixel (ici 28x28)\n",
    "NB_EPOCHS_DENOISE = 40               # nombre epoch alogithme debruiter\n",
    "BATCH_SIZE        = 4            # taille batch de traitement\n",
    "SAVE_MODEL_DENOISE = \"denoiser.h5\"     # sauvegarde du modele de debruitage\n",
    "\n",
    "def process(image):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Import du .env\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "# Chargement du .env !!!!!!!!!!!! CHANGER LE PATH !!!!!!!!!!!!!!\n",
    "# Renvoie true si le .env est chargé\n",
    "dotenv.load_dotenv('/home/cesi/datascience/.env.local')\n",
    "\n",
    "models_path = os.environ.get('MODELS_PATH_LIVRABLE2')\n",
    "sys.path.insert(0, models_path)\n",
    "\n",
    "import builder_vae\n",
    "import homemade\n",
    "import test2\n",
    "import resnet\n",
    "import test3\n",
    "\n",
    "\n",
    "SAVE_WEIGHTS_PATH = os.environ.get('WEIGHT_PATH_LIVRABLE2')\n",
    "SOURCE_LIVRABLE2_PATH = os.getenv(\"SOURCE_LIVRABLE2_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test = image_dataset_from_directory(\n",
    "    SOURCE_LIVRABLE2_PATH,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    # label_mode=None,\n",
    "    shuffle=False,\n",
    "    validation_split=0.9,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "x_train = x_train.map(lambda x,y: (x/255,y))\n",
    "x_test = x_test.map(lambda x,y: (x/255,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpI6DFBd3z2Y"
   },
   "source": [
    "Commençons par écrire une fonction qui permet de visualiser $n$ premiers enregistrements en noir et blanc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHzo3fUG3z2Y"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import uniform\n",
    "import tensorflow as tf\n",
    "# os.chdir(r'/tf')\n",
    "from keras_cv.layers import RandomGaussianBlur\n",
    "\n",
    "def add_noise(img, perturbation_conf):\n",
    "    pertubation = perturbation_conf['perturbation']\n",
    "    noised_img = img\n",
    "    if pertubation == 1:\n",
    "        blur_kernel_value = perturbation_conf['blur_kernel_size']\n",
    "        noised_img = RandomGaussianBlur(kernel_size=blur_kernel_value, factor=(0.5, 3))(noised_img)\n",
    "    elif pertubation == 2:\n",
    "        noise_value = perturbation_conf['noise_factor']\n",
    "        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=noise_value/255, dtype=tf.float32)\n",
    "        noised_img = tf.cast(img, tf.float32) + noise\n",
    "    elif pertubation == 3:\n",
    "        noise_value = perturbation_conf['noise_factor']\n",
    "        blur_kernel_value = perturbation_conf['blur_kernel_size']\n",
    "        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=noise_value/255, dtype=tf.float32)\n",
    "        noised_img = tf.cast(img, tf.float32) + noise\n",
    "        noised_img = RandomGaussianBlur(kernel_size=blur_kernel_value, factor=(0.5, 1))(noised_img)\n",
    "    else:\n",
    "        noised_img = img\n",
    "        \n",
    "    return noised_img, img\n",
    "\n",
    "\n",
    "noise_configuration = {\n",
    "    0:{\n",
    "    'perturbation': 1,\n",
    "    'blur_kernel_size': 6,\n",
    "    },\n",
    "    1:{\n",
    "    'perturbation': 2,\n",
    "    'noise_factor': 20\n",
    "    },\n",
    "    2:{\n",
    "    'perturbation': 3,\n",
    "    'noise_factor': 12,\n",
    "    'blur_kernel_size': 2\n",
    "    },\n",
    "    3:{\n",
    "    'perturbation': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "x_train_noisy = x_train.map(lambda x,y: (add_noise(x, noise_configuration[1])))\n",
    "x_test_noisy = x_test.map(lambda x,y: (add_noise(x, noise_configuration[1])))\n",
    "\n",
    "x_train_blur = x_train.map(lambda x,y: (add_noise(x, noise_configuration[0])))\n",
    "x_test_blur = x_test.map(lambda x,y: (add_noise(x, noise_configuration[0])))\n",
    "\n",
    "x_train_noise_blur = x_train.map(lambda x,y: (add_noise(x, noise_configuration[2])))\n",
    "x_test_noise_blur = x_test.map(lambda x,y: (add_noise(x, noise_configuration[2])))\n",
    "\n",
    "x_train_clean = x_train.map(lambda x,y: (add_noise(x, noise_configuration[3])))\n",
    "x_test_clean = x_test.map(lambda x,y: (add_noise(x, noise_configuration[3])))\n",
    "\n",
    "random_train_set = x_train_clean.concatenate(x_train_noisy).concatenate(x_train_blur).concatenate(x_train_noise_blur)\n",
    "random_test_set = x_test_clean.concatenate(x_test_noisy).concatenate(x_test_blur).concatenate(x_test_noise_blur)\n",
    "\n",
    "\n",
    "# display three images on a single row with matplotlib \n",
    "def display_images(*images):\n",
    "    \"\"\"Display images on a single row.\"\"\"\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), index+1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uLTS74F3z2Z"
   },
   "source": [
    "Voyons ce que ça donne :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PC02d4V3z2s",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_CHOSEN = 'test2'\n",
    "\n",
    "def load_model(model_choosen):\n",
    "    match(model_choosen):\n",
    "        case 'homemade':\n",
    "            model = homemade.build(IMG_SIZE)\n",
    "        case 'vae':\n",
    "            model = builder_vae.build(IMG_SIZE, 64)\n",
    "        case 'test2':\n",
    "            model = test2.build(IMG_SIZE)\n",
    "        case 'test3':\n",
    "            model = test3.build(IMG_SIZE)\n",
    "        case 'resnet':\n",
    "            model = resnet.build(IMG_SIZE)\n",
    "    return model\n",
    "autoencoder = load_model(MODEL_CHOSEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4w2DyFE3z3M"
   },
   "source": [
    "### Entrainement de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHnPwSlj3z3N"
   },
   "source": [
    "On va ensuite entraîner l'auto-encodeur en utilisant les constantes définit au début (`NB_EPOCHS_DENOISE,BATCH_SIZE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLeiM12J7shx",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# path = createTrainingData.create_training_data(weight_path, model, model_choosen, num_classes, image_h, image_w, batch_size)\n",
    "\n",
    "# checkpoint_path = path+\"/cp-{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# weights_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_path,\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     save_freq='epoch')\n",
    "\n",
    "# history = model.fit(train_set, epochs=epochs, validation_data=test_set, callbacks=[weights_callback])\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    random_train_set,\n",
    "    epochs=1,\n",
    "    shuffle=True,\n",
    "    validation_data=random_test_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZEugG4_AKzb"
   },
   "source": [
    "Affichez maintenant la courbe d'apprentissage. Que pensez-vous des performances du modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(3)\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.savefig(SAVE_WEIGHTS_PATH + MODEL_CHOSEN + '/training_400.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_path = SAVE_WEIGHTS_PATH + MODEL_CHOSEN + '/weights_400.h5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = {\n",
    "    'noisy': x_test_noisy.take(10),\n",
    "    'blur': x_test_blur.take(10),\n",
    "    'noise_blur': x_test_noise_blur.take(10),\n",
    "    'clean': x_test_clean.take(10),\n",
    "    # 'overall': random_test_set\n",
    "}\n",
    "results = {}\n",
    "accuracy = {}\n",
    "loss = {}\n",
    "for test_set_name in test_sets:\n",
    "    loss[test_set_name], accuracy[test_set_name] = autoencoder.evaluate(test_sets[test_set_name])\n",
    "accuracy['overall'] = np.mean(list(accuracy.values()))\n",
    "loss['overall'] = np.mean(list(loss.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "bars = plt.bar(range(len(accuracy)), list(accuracy.values()), align='center', color=colors, alpha=0.8, width=0.5)\n",
    "plt.xticks(range(len(accuracy)), list(accuracy.keys()))\n",
    "\n",
    "plt.title('Accuracy for each test set')\n",
    "plt.savefig(SAVE_WEIGHTS_PATH+\"resnet/accuracy_400.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(range(len(loss)), list(loss.values()), align='center', color=colors, alpha=0.8, width=0.5)\n",
    "plt.xticks(range(len(loss)), list(loss.keys()))\n",
    "plt.title('Loss for each test set')\n",
    "plt.savefig(SAVE_WEIGHTS_PATH+\"resnet/loss_400.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicitions = autoencoder.predict(random_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_index in range(3,6):\n",
    "    # pred = predicitions[img_index]\n",
    "    original = list(x_test_clean.take(1).as_numpy_iterator())[0][0][img_index]\n",
    "    noisy = list(x_test_noisy.take(1).as_numpy_iterator())[0][0][img_index]\n",
    "    pred = autoencoder.predict(list(x_test_clean.take(1).as_numpy_iterator())[0][0])[img_index]\n",
    "\n",
    "    display_images(original, noisy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Oib6nOUB_t-A",
    "outputId": "5bbf833e-0879-4dd6-f290-3e4b604f971d"
   },
   "outputs": [],
   "source": [
    "# Visualisation des pertes d'apprentissage (Train) et de validation (Test)\n",
    "plt.plot( #A COMPLETER\n",
    "         label='train')\n",
    "plt.plot( #A COMPLETER\n",
    "         label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isdgF8Fw3z3W"
   },
   "source": [
    "Que pensez-vous des performances du modèle ?\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "\n",
    "# 1.4 Sauvgarde de l'auto-encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lacVdNs93z3Y"
   },
   "source": [
    "L'entrainement de l'auto-encodeur sans utilisation de puissance de calcul (GPU) peut prendre beaucoup de temps. Usuellement, nous sauvegardons le modèle entraîné en local ou sur un serveur distant pour l'utiliser ultérieurement afin de traiter les nouvelles données (d'ailleurs, vous verrez une utilisation avancée de cette technique, le transfert learning, dès la semaine prochaine).\n",
    "Pour sauvegarder le modèle `autoencoder`, utiliser la méthode `save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH0sl-AZ3z3Z"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "#A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgZ7ckxd3z3a"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = #A COMPLETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "qjbGN2FX3z3a",
    "outputId": "b96c53b9-2af7-4f7d-8ab5-9fd55ae77504"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IEX6qSH3z3b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "sgKOfLjd3z3b"
   ],
   "name": "WS 2.3 - Autoencodeur et traitement d'image- Tuteur.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
