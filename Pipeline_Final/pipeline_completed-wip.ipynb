{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# reload des .py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from keras_cv.layers import RandomGaussianBlur\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from random import randint, seed\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv('/tf/science-de-la-donnee/Pipeline_Final/.env')\n",
    "\n",
    "# ---------------| PATHS |--------------- #\n",
    "# CHANGER LES PATHS DANS LE FICHIER .env !!!!!!!!!!!!!!\n",
    "data_dir = os.environ.get('DATA_PATH')\n",
    "script_path = os.environ.get('SCRIPT_PATH')\n",
    "weight_path = os.environ.get('WEIGHT_PATH')\n",
    "models_path = os.environ.get('MODELS_PATH')\n",
    "\n",
    "output_folder_classification = os.environ.get('OUTPUT_PATH_CLASSIFICATION')\n",
    "output_folder_autoencoder = os.environ.get('OUTPUT_PATH_AUTOENCODER')\n",
    "\n",
    "sys.path.insert(0, script_path)\n",
    "sys.path.insert(1, models_path)\n",
    "\n",
    "# scripts\n",
    "import checkImage\n",
    "import createTrainingData\n",
    "import displayImage\n",
    "import plotPrediction\n",
    "import plotResults\n",
    "import processImage\n",
    "import plotImage\n",
    "\n",
    "# models\n",
    "import resnet50\n",
    "import test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------| VARIABLES |--------------- #\n",
    "\n",
    "# Vérfication des images\n",
    "check_images = False\n",
    "\n",
    "model_choosen = 'resnet50'\n",
    "\n",
    "# Taille de l'image (resacaling)\n",
    "image_h, image_w = 448, 448\n",
    "image_size = (image_h, image_w)\n",
    "# Taille des batchs\n",
    "batch_size_classification = 1\n",
    "\n",
    "# Minimum de pixels pour que l'image soit considérée comme une image\n",
    "min_h = 25\n",
    "min_w = 25\n",
    "\n",
    "# Nombre d'epochs\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "IMG_SIZE_AUTOENCODER          = 400             # taille coté final d'une image en pixel (ici 224x224)\n",
    "NB_EPOCHS_AUTOENCODER = 3               # nombre epoch alogithme debruiter\n",
    "BATCH_SIZE_AUTOENCODER        = 8            # taille batch de traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pré-tri des images (celle qui sont corompus sont écartées)\n",
    "if check_images:\n",
    "    checkImage.checkImage(data_dir, min_h, min_w)\n",
    "\n",
    "image_dir = data_dir\n",
    "\n",
    "# Utilisez ImageDataGenerator pour charger les images\n",
    "datagen = ImageDataGenerator()  # Normalisation des pixels\n",
    "\n",
    "image_generator = datagen.flow_from_directory(\n",
    "    image_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size_classification,\n",
    "    shuffle=False  # Assurez-vous que les images sont dans le bon ordre\n",
    ")\n",
    "\n",
    "def load_model(model_choosen):\n",
    "    match(model_choosen):\n",
    "        case 'resnet50':\n",
    "            model = resnet50.build((image_h, image_w), 2)\n",
    "    return model\n",
    "\n",
    "model = load_model(model_choosen)\n",
    "\n",
    "# model = tf.keras.models.load_model(models_path+'/resnet50.keras')\n",
    "model.load_weights(weight_path+\"/classification/cp-0002.ckpt\")\n",
    "\n",
    "# Effectuez des prédictions sur les images\n",
    "predictions = model.predict(image_generator)\n",
    "\n",
    "image_dir = data_dir+\"/dataset\"\n",
    "\n",
    "# Créer un dictionnaire pour associer les noms de fichiers aux prédictions\n",
    "image_predictions = {}\n",
    "\n",
    "# Obtenir la liste des noms de fichiers d'images triés\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "\n",
    "for i in range(len(image_files)):\n",
    "    # Récupérer le nom de fichier\n",
    "    filename = image_files[i]\n",
    "\n",
    "    # Récupérer la prédiction pour cette image\n",
    "    prediction = predictions[i][0]  # Extrait la valeur scalaire\n",
    "\n",
    "    # Stocker le nom de fichier et la prédiction dans le dictionnaire\n",
    "    image_predictions[filename] = prediction\n",
    "\n",
    "photos, not_photos = plotImage.plot_images_with_highlight(predictions, image_generator,output_folder_classification, label_value=1)\n",
    "\n",
    "# Copier coller les valeurs prédictes dans le dossier output\n",
    "import shutil\n",
    "import os\n",
    "# Check if folder of photo exists, if not create it\n",
    "if not os.path.exists(output_folder_classification+\"/dataset/Photo/dataset\"):\n",
    "    os.makedirs(output_folder_classification+\"/dataset/Photo/dataset\")\n",
    "else:\n",
    "    # remove all files in folder\n",
    "    for file in os.listdir(output_folder_classification+\"/dataset/Photo/dataset\"):\n",
    "        os.remove(output_folder_classification+\"/dataset/Photo/dataset/\"+file)\n",
    "\n",
    "for photo in photos:\n",
    "    shutil.copy(data_dir+photo, output_folder_classification+\"/dataset/Photo/\"+photo)\n",
    "\n",
    "# Check if folder of photo exists, if not create it\n",
    "if not os.path.exists(output_folder_classification+\"/dataset/NotPhoto\"):\n",
    "    os.makedirs(output_folder_classification+\"/dataset/NotPhoto\")\n",
    "else:\n",
    "    # remove all files in folder\n",
    "    for file in os.listdir(output_folder_classification+\"/dataset/NotPhoto\"):\n",
    "        os.remove(output_folder_classification+\"/dataset/NotPhoto/\"+file)\n",
    "\n",
    "for photo in not_photos:\n",
    "    shutil.copy(data_dir+photo, output_folder_classification+\"/dataset/NotPhoto/\"+photo.replace(\"dataset/\", \"\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising\n",
    "\n",
    "# ---------------| VARIABLES |--------------- #\n",
    "data_dir_autotoencoder = output_folder_classification\n",
    "output_dir_autotoencoder = os.environ.get('OUTPUT_PATH_AUTOENCODER')\n",
    "\n",
    "MODEL_CHOSEN = \"autoencoder_no_pooling\"\n",
    "\n",
    "\n",
    "def load_model(model_choosen):\n",
    "    match(model_choosen):\n",
    "        # case 'autoencoder_pooling':\n",
    "        #     model = homemade.build(IMG_SIZE)\n",
    "        case 'autoencoder_no_pooling':\n",
    "            model = test2.build(IMG_SIZE_AUTOENCODER)\n",
    "        # case 'resnet':\n",
    "        #     model = resnet.build(IMG_SIZE)\n",
    "    return model\n",
    "autoencoder = load_model(MODEL_CHOSEN)\n",
    "\n",
    "autoencoder.load_weights(weight_path + '/autoencoder/weights_400_2.h5')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "image_generator_autoencoder = datagen.flow_from_directory(\n",
    "    data_dir_autotoencoder+\"/dataset/Photo\",\n",
    "    target_size=(IMG_SIZE_AUTOENCODER,IMG_SIZE_AUTOENCODER),\n",
    "    batch_size=BATCH_SIZE_AUTOENCODER,\n",
    "    shuffle=False  # Assurez-vous que les images sont dans le bon ordre\n",
    ")\n",
    "\n",
    "original_image_paths = image_generator_autoencoder.filenames\n",
    "\n",
    "# Check if folder of photo exists, if not create it\n",
    "if not os.path.exists(output_folder_autoencoder+\"/denoised_dataset\"):\n",
    "    os.makedirs(output_folder_autoencoder+\"/denoised_dataset\")\n",
    "else:\n",
    "    # remove all files in folder\n",
    "    for file in os.listdir(output_folder_autoencoder+\"/denoised_dataset\"):\n",
    "        os.remove(output_folder_autoencoder+\"/denoised_dataset/\"+file)\n",
    "\n",
    "import imageio\n",
    "\n",
    "for img_index in range(0,len(image_generator_autoencoder)):\n",
    "    if img_index < len(predictions):\n",
    "        original_batch = image_generator_autoencoder[img_index][0]\n",
    "        denoised_batch = autoencoder.predict(original_batch)\n",
    "\n",
    "    # Parcourez les images dans le batch\n",
    "    for batch_index in range(len(original_batch)):\n",
    "        if batch_index < len(original_batch):\n",
    "            original = original_batch[batch_index]\n",
    "            denoised = denoised_batch[batch_index]\n",
    "\n",
    "            # Récupérez le nom de l'image d'origine\n",
    "            original_filename = os.path.basename(original_image_paths[img_index * BATCH_SIZE_AUTOENCODER + batch_index])\n",
    "\n",
    "            denoised_image_path = os.path.join(output_folder_autoencoder, \"denoised_dataset\", \"denoised_\" + original_filename)\n",
    "\n",
    "            # Convertissez l'image \"denoised\" au format 8 bits par canal (0-255)\n",
    "            denoised = (denoised * 220.0).astype(np.uint8)\n",
    "\n",
    "            # Enregistrez l'image \"denoised\" sous forme de fichier\n",
    "            imageio.imsave(denoised_image_path, denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def classification(DATA_PATH):\n",
    "    \n",
    "    def parcourir_dossier():\n",
    "        dossier_selectionne = filedialog.askdirectory()\n",
    "        if dossier_selectionne:\n",
    "            fichier_ou_dossier_var.set(dossier_selectionne)\n",
    "\n",
    "    def confirmer():\n",
    "        # Vous pouvez ajouter ici la logique pour traiter les données et effectuer la classification\n",
    "        # Pour l'instant, affichons simplement les valeurs sélectionnées\n",
    "        result_text = f\"Chemin du fichier/dossier : {fichier_ou_dossier_var.get()}\\n\"\n",
    "        result_text += f\"Hauteur de l'image : {input_image_size.get()}\\n\"\n",
    "        result_text += f\"Largeur de l'image : {input_image_width.get()}\\n\"\n",
    "        result_text += f\"Hauteur de l'image minimale : {input_min_image_size.get()}\\n\"\n",
    "        result_text += f\"Largeur de l'image minimale : {input_min_image_width.get()}\\n\"\n",
    "        result_text += f\"Modèle de classification : {input_model.get()}\\n\"\n",
    "        result_text += f\"Taille du batch : {input_batch_size.get()}\\n\"\n",
    "        result_text += f\"Nombre d'epochs : {input_epochs.get()}\\n\"\n",
    "        result_text += f\"Check d'image : {check_image_var.get()}\\n\"\n",
    "        result_text += f\"Type de classification : {classification_var.get()}\\n\"\n",
    "        label_result.config(text=result_text)\n",
    "\n",
    "    fenetre = tk.Tk()\n",
    "    fenetre.title(\"Interface Tkinter\")\n",
    "    fenetre.geometry(\"500x700\")\n",
    "\n",
    "    titre = tk.Label(fenetre, text=\"Classification\", font=(\"Helvetica\", 16))\n",
    "    titre.pack(pady=10)\n",
    "\n",
    "    separator = ttk.Separator(fenetre, orient='horizontal')\n",
    "    separator.pack(fill='x')\n",
    "\n",
    "    classification_frame = tk.Frame(fenetre)\n",
    "    classification_frame.pack(pady=5)\n",
    "    label_classification = tk.Label(classification_frame, text=\"Classification\")\n",
    "    label_classification.pack(side=tk.LEFT)\n",
    "\n",
    "    fichier_ou_dossier_var = tk.StringVar()\n",
    "    fichier_ou_dossier_var.set(DATA_PATH)  # Texte de placeholder\n",
    "    fichier_ou_dossier_entry = tk.Entry(fenetre, textvariable=fichier_ou_dossier_var, width=40)\n",
    "    fichier_ou_dossier_entry.pack(pady=5)\n",
    "    bouton_parcourir = tk.Button(fenetre, text=\"Parcourir\", command=parcourir_dossier)\n",
    "    bouton_parcourir.pack()\n",
    "\n",
    "    label_image_size = tk.Label(fenetre, text=\"Hauteur de l'image:\")\n",
    "    label_image_size.pack()\n",
    "    input_image_size = tk.Entry(fenetre)\n",
    "    input_image_size.pack(pady=5)\n",
    "\n",
    "    label_image_width = tk.Label(fenetre, text=\"Largeur de l'image:\")\n",
    "    label_image_width.pack()\n",
    "    input_image_width = tk.Entry(fenetre)\n",
    "    input_image_width.pack(pady=5)\n",
    "\n",
    "    label_min_image_size = tk.Label(fenetre, text=\"Hauteur de l'image minimale:\")\n",
    "    label_min_image_size.pack()\n",
    "    input_min_image_size = tk.Entry(fenetre)\n",
    "    input_min_image_size.pack(pady=5)\n",
    "\n",
    "    label_min_image_width = tk.Label(fenetre, text=\"Largeur de l'image minimale:\")\n",
    "    label_min_image_width.pack()\n",
    "    input_min_image_width = tk.Entry(fenetre)\n",
    "    input_min_image_width.pack(pady=5)\n",
    "\n",
    "    label_model = tk.Label(fenetre, text=\"Modèle de classification:\")\n",
    "    label_model.pack()\n",
    "    input_model = tk.Entry(fenetre)\n",
    "    input_model.pack(pady=5)\n",
    "\n",
    "    label_batch_size = tk.Label(fenetre, text=\"Taille du batch:\")\n",
    "    label_batch_size.pack()\n",
    "    input_batch_size = tk.Entry(fenetre)\n",
    "    input_batch_size.pack(pady=5)\n",
    "\n",
    "    label_epochs = tk.Label(fenetre, text=\"Nombre d'epochs:\")\n",
    "    label_epochs.pack()\n",
    "    input_epochs = tk.Entry(fenetre)\n",
    "    input_epochs.pack(pady=5)\n",
    "\n",
    "    check_image_var = tk.IntVar()\n",
    "    check_image_button = tk.Checkbutton(fenetre, text=\"Check d'image\", variable=check_image_var)\n",
    "    check_image_button.pack(pady=5)\n",
    "\n",
    "    classification_var = tk.StringVar()\n",
    "    classification_var.set(\"Binaire\")\n",
    "    label_classification_type = tk.Label(fenetre, text=\"Type de classification:\")\n",
    "    label_classification_type.pack()\n",
    "    classification_binaire_button = tk.Radiobutton(fenetre, text=\"Binaire\", variable=classification_var, value=\"Binaire\")\n",
    "    classification_multi_classes_button = tk.Radiobutton(fenetre, text=\"Multi-classes\", variable=classification_var, value=\"Multi-classes\")\n",
    "    classification_binaire_button.pack()\n",
    "    classification_multi_classes_button.pack()\n",
    "\n",
    "    bouton = tk.Button(fenetre, text=\"Confirmer\", command=confirmer)\n",
    "    bouton.pack(pady=10)\n",
    "\n",
    "    label_result = tk.Label(fenetre, text=\"\")\n",
    "    label_result.pack(pady=10)\n",
    "\n",
    "    fenetre.mainloop()\n",
    "\n",
    "classification(\"DATA_PATH\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
